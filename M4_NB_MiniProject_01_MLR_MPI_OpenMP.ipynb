{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7rc1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imranahmed123/DataScience-AI-ML/blob/main/M4_NB_MiniProject_01_MLR_MPI_OpenMP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heated-queens"
      },
      "source": [
        "# Advanced Certification Program in Computational Data Science\n",
        "## A program by IISc and TalentSprint\n",
        "### Mini-Project: Implementation of Multiple Linear Regression using MPI and OpenMP"
      ],
      "id": "heated-queens"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "military-proportion"
      },
      "source": [
        "## Learning Objectives"
      ],
      "id": "military-proportion"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "durable-grounds"
      },
      "source": [
        "At the end of the mini-project, you will be able to :\n",
        "\n",
        "* understand the collective communication operations like scatter, gather, broadcast\n",
        "* understand the blocking and non-blocking communication\n",
        "* implement multiple linear regression and run it using MPI\n",
        "* implement the multiple linear regression based predictions using OpenMP"
      ],
      "id": "durable-grounds"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "growing-queens"
      },
      "source": [
        "### Dataset"
      ],
      "id": "growing-queens"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLwz-D_xVT8o"
      },
      "source": [
        "The dataset chosen for this mini-project is [Combined Cycle Power Plant](https://archive.ics.uci.edu/ml/datasets/combined+cycle+power+plant). The dataset is made up of 9568 records and 5 columns. Each record contains the values for Ambient Temperature, Exhaust Vaccum, Ambient Pressure, Relative Humidity and Energy Output.\n",
        "\n",
        "Predicting full load electrical power output of a base load power plant is important in order to maximize the profit from the available megawatt hours.  The base load operation of a power plant is influenced by four main parameters, which are used as input variables in the dataset, such as ambient temperature, atmospheric pressure, relative humidity, and exhaust steam pressure. These parameters affect electrical power output, which is considered as the target variable.\n",
        "\n",
        "**Note:** The data was collected over a six year period (2006-11)."
      ],
      "id": "yLwz-D_xVT8o"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dominant-residence"
      },
      "source": [
        "## Information"
      ],
      "id": "dominant-residence"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coated-timing"
      },
      "source": [
        "#### MPI in a Nutshell\n",
        "\n",
        "MPI stands for \"Message Passing Interface\". It is a library of functions (in C / Python) or subroutines (in Fortran) that you insert into source code to perform data communication between processes. MPI was developed over two years of discussions led by the MPI Forum, a group of roughly sixty people representing some forty organizations.\n",
        "\n",
        "To know more about MPI click [here](https://hpc-tutorials.llnl.gov/mpi/)\n",
        "\n",
        "\n",
        "#### Multiple Linear Regression\n",
        "\n",
        "Multiple regression is an extension of simple linear regression. It is used when we want to predict the value of a variable based on the value of two or more other variables. The variable we want to predict is called the dependent variable (or sometimes, the outcome, target or criterion variable). The variables we are using to predict the value of the dependent variable are called the independent variables (or sometimes, the predictor, explanatory or regressor variables)."
      ],
      "id": "coated-timing"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "global-savings"
      },
      "source": [
        "**Note:** We will be using the mpi4py Python package for MPI based code implementation"
      ],
      "id": "global-savings"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndQNKsjS7c04"
      },
      "source": [
        "## Grading = 20 Points"
      ],
      "id": "ndQNKsjS7c04"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "green-deviation"
      },
      "source": [
        "**Run the below code to install mpi4py package**"
      ],
      "id": "green-deviation"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "designing-marketing",
        "scrolled": true,
        "outputId": "56d11993-6408-4995-8cbd-822b1824535f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install mpi4py"
      ],
      "id": "designing-marketing",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mpi4py\n",
            "  Downloading mpi4py-4.0.0.tar.gz (464 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.8/464.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-4.0.0-cp310-cp310-linux_x86_64.whl size=4266268 sha256=373ecdd98ca9e0a9f4e9fba480ffa9516fcc485f87d8a1011a27349ac4918d83\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/17/12/83db63ee0ae5c4b040ee87f2e5c813aea4728b55ec6a37317c\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dedicated-thong"
      },
      "source": [
        "#### Importing Necessary Packages"
      ],
      "id": "dedicated-thong"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reported-acrobat",
        "scrolled": true
      },
      "source": [
        "# Importing pandas\n",
        "import pandas as pd\n",
        "# Importing Numpy\n",
        "import numpy as np\n",
        "# Importing MPI from mpi4py package\n",
        "from mpi4py import MPI\n",
        "# Importing sqrt function from the Math\n",
        "from math import sqrt\n",
        "# Importing Decimal, ROUND_HALF_UP functions from the decimal package\n",
        "from decimal import Decimal, ROUND_HALF_UP\n",
        "import time"
      ],
      "id": "reported-acrobat",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "standing-zimbabwe"
      },
      "source": [
        "#### Downloading the data"
      ],
      "id": "standing-zimbabwe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "universal-jonathan",
        "scrolled": true
      },
      "source": [
        "#@title Download the data\n",
        "!wget -qq https://cdn.iisc.talentsprint.com/CDS/Datasets/PowerPlantData.csv"
      ],
      "id": "universal-jonathan",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "forty-still"
      },
      "source": [
        "### Overview\n",
        "\n",
        "* Load the data and perform data pre-processing\n",
        "* Identify the features, target and split the data into train and test\n",
        "* Implement multiple Linear Regression by estimating the coefficients on the given data\n",
        "* Use MPI package to distribute the data and implement `communicator`\n",
        "* Define functions for each objective and make a script (.py) file to execute using MPI command\n",
        "* Use OpenMP component to predict the data and calculate the error on the predicted data\n",
        "* Implement the Linear Regression from `sklearn` and compare the results"
      ],
      "id": "forty-still"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "early-peace"
      },
      "source": [
        "#### Exercise 1: Load data (1 point)\n",
        "\n",
        "Write a function that takes the filename as input and loads the data in a pandas dataframe with the column names as Ambient Temperature, Exhaust Vaccum, Ambient Pressure, Relative Humidity and Energy Output respectively.\n",
        "\n",
        "**Hint:** read_csv()\n"
      ],
      "id": "early-peace"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "differential-vacation",
        "scrolled": true
      },
      "source": [
        "FILENAME = \"/content/PowerPlantData.csv\" # File path\n",
        "\n",
        "# YOUR CODE HERE to Define a function to load the data"
      ],
      "id": "differential-vacation",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_data(filename):\n",
        "    \"\"\"\n",
        "    This function loads the data from a CSV file into a pandas DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    filename (str): The path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: A DataFrame containing the data with the specified column names.\n",
        "    \"\"\"\n",
        "    # Define the column names\n",
        "    column_names = ['Ambient Temperature', 'Exhaust Vaccum', 'Ambient Pressure', 'Relative Humidity', 'Energy Output']\n",
        "\n",
        "    # Load the data into a DataFrame with the specified column names\n",
        "    data = pd.read_csv(filename, header=None, names=column_names)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Now call the function after it's been defined\n",
        "FILENAME = \"/content/PowerPlantData.csv\"  # Update this path if needed\n",
        "data = load_data(FILENAME)\n",
        "print(data.head())  # Display the first few rows\n"
      ],
      "metadata": {
        "id": "iV6KcaQs8FyL",
        "outputId": "3f2b9e96-fd03-494e-e830-6c3396e5f280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "iV6KcaQs8FyL",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Ambient Temperature Exhaust Vaccum Ambient Pressure Relative Humidity  \\\n",
            "0                  AT              V               AP                RH   \n",
            "1                8.34          40.77          1010.84             90.01   \n",
            "2               23.64          58.49           1011.4              74.2   \n",
            "3               29.74           56.9          1007.15             41.91   \n",
            "4               19.07          49.69          1007.22             76.79   \n",
            "\n",
            "  Energy Output  \n",
            "0            PE  \n",
            "1        480.48  \n",
            "2        445.75  \n",
            "3        438.76  \n",
            "4        453.09  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "italian-expense"
      },
      "source": [
        "#### Exercise 2: Explore data (1 point)\n",
        "\n",
        "Write a function that takes the data loaded using the above defined function as input and explore it.\n",
        "\n",
        "**Hint:** You can define and check for following things in the dataset inside a function\n",
        "\n",
        "- checking for the number of rows and columns\n",
        "- summary of the dataset\n",
        "- check for the null values\n",
        "- check for the duplicate values"
      ],
      "id": "italian-expense"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "local-quarter",
        "scrolled": true
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "local-quarter",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def explore_data(data):\n",
        "    \"\"\"\n",
        "    This function takes a pandas DataFrame as input and provides an exploration summary\n",
        "    including the number of rows and columns, dataset summary, and checks for null and duplicate values.\n",
        "\n",
        "    Parameters:\n",
        "    data (pandas.DataFrame): The input DataFrame to explore.\n",
        "\n",
        "    Returns:\n",
        "    None: The function prints the exploration details.\n",
        "    \"\"\"\n",
        "    # Checking the number of rows and columns\n",
        "    print(\"Number of rows and columns:\", data.shape)\n",
        "\n",
        "    # Summary of the dataset\n",
        "    print(\"\\nSummary of the dataset:\")\n",
        "    print(data.describe())\n",
        "\n",
        "    # Check for null values\n",
        "    print(\"\\nChecking for null values:\")\n",
        "    print(data.isnull().sum())\n",
        "\n",
        "    # Check for duplicate values\n",
        "    duplicate_count = data.duplicated().sum()\n",
        "    print(\"\\nNumber of duplicate rows:\", duplicate_count)\n",
        "\n",
        "    if duplicate_count > 0:\n",
        "        print(\"There are duplicate rows in the dataset.\")\n",
        "    else:\n",
        "        print(\"There are no duplicate rows in the dataset.\")\n"
      ],
      "metadata": {
        "id": "S7_rkYBt8PfM"
      },
      "id": "S7_rkYBt8PfM",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "FILENAME = \"/content/PowerPlantData.csv\"  # Update this path if needed\n",
        "data = load_data(FILENAME)\n",
        "\n",
        "# Explore the loaded data\n",
        "explore_data(data)\n"
      ],
      "metadata": {
        "id": "5ojhKIV48Wej",
        "outputId": "4f83ab82-e3df-4ff5-82b4-e7d8cf67f1e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5ojhKIV48Wej",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows and columns: (9569, 5)\n",
            "\n",
            "Summary of the dataset:\n",
            "       Ambient Temperature Exhaust Vaccum Ambient Pressure Relative Humidity  \\\n",
            "count                 9569           9569             9569              9569   \n",
            "unique                2774            635             2518              4547   \n",
            "top                  25.21          70.32          1013.88            100.09   \n",
            "freq                    14             61               16                26   \n",
            "\n",
            "       Energy Output  \n",
            "count           9569  \n",
            "unique          4837  \n",
            "top            468.8  \n",
            "freq               9  \n",
            "\n",
            "Checking for null values:\n",
            "Ambient Temperature    0\n",
            "Exhaust Vaccum         0\n",
            "Ambient Pressure       0\n",
            "Relative Humidity      0\n",
            "Energy Output          0\n",
            "dtype: int64\n",
            "\n",
            "Number of duplicate rows: 41\n",
            "There are duplicate rows in the dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whole-retailer"
      },
      "source": [
        "#### Exercise 3: Handle missing data (1 point)\n",
        "\n",
        "After exploring the dataset if there are any null values present in the dataset then define a function that takes data loaded using the above defined function as input and handle the null values accordingly.\n",
        "\n",
        "**Hint:**\n",
        "\n",
        "- Drop the records containing the null values - dropna()\n",
        "- Replace the null values with the mean/median/mode - fillna()"
      ],
      "id": "whole-retailer"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "incorporated-child",
        "scrolled": true
      },
      "source": [
        "# Function to handle missing data\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "id": "incorporated-child",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_missing_data(data, method='drop', fill_value=None):\n",
        "    \"\"\"\n",
        "    This function handles missing data in the DataFrame according to the specified method.\n",
        "\n",
        "    Parameters:\n",
        "    data (pandas.DataFrame): The input DataFrame to handle missing values.\n",
        "    method (str): The method to handle missing values. Options are:\n",
        "                  'drop' - Drop rows with missing values.\n",
        "                  'mean' - Replace missing values with the mean of the column.\n",
        "                  'median' - Replace missing values with the median of the column.\n",
        "                  'mode' - Replace missing values with the mode of the column.\n",
        "    fill_value: A specific value to fill missing data, only if provided and method is 'custom'.\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: A DataFrame with missing data handled.\n",
        "    \"\"\"\n",
        "    # Convert columns to numeric, coerce errors to NaN\n",
        "    data = data.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    if method == 'drop':\n",
        "        # Drop rows with missing values\n",
        "        data = data.dropna()\n",
        "    elif method == 'mean':\n",
        "        # Replace missing values with the mean of each column\n",
        "        data = data.fillna(data.mean())\n",
        "    elif method == 'median':\n",
        "        # Replace missing values with the median of each column\n",
        "        data = data.fillna(data.median())\n",
        "    elif method == 'mode':\n",
        "        # Replace missing values with the mode of each column\n",
        "        data = data.fillna(data.mode().iloc[0])\n",
        "    elif method == 'custom' and fill_value is not None:\n",
        "        # Replace missing values with a specific value\n",
        "        data = data.fillna(fill_value)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid method or fill_value. Please choose from 'drop', 'mean', 'median', 'mode', or 'custom' with a fill value.\")\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "gh5eOij88jY8"
      },
      "id": "gh5eOij88jY8",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "FILENAME = \"/content/PowerPlantData.csv\"  # Update this path if needed\n",
        "data = load_data(FILENAME)\n",
        "\n",
        "# Explore the loaded data\n",
        "explore_data(data)\n",
        "\n",
        "# Handle missing data (e.g., replacing with the mean)\n",
        "data_handled = handle_missing_data(data, method='mean')\n",
        "\n",
        "# Explore the data again to ensure missing data is handled\n",
        "explore_data(data_handled)\n"
      ],
      "metadata": {
        "id": "kvzX4Gsu8lLE",
        "outputId": "8cd47976-85a6-4ec8-cf75-4d26c6d5e8bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kvzX4Gsu8lLE",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows and columns: (9569, 5)\n",
            "\n",
            "Summary of the dataset:\n",
            "       Ambient Temperature Exhaust Vaccum Ambient Pressure Relative Humidity  \\\n",
            "count                 9569           9569             9569              9569   \n",
            "unique                2774            635             2518              4547   \n",
            "top                  25.21          70.32          1013.88            100.09   \n",
            "freq                    14             61               16                26   \n",
            "\n",
            "       Energy Output  \n",
            "count           9569  \n",
            "unique          4837  \n",
            "top            468.8  \n",
            "freq               9  \n",
            "\n",
            "Checking for null values:\n",
            "Ambient Temperature    0\n",
            "Exhaust Vaccum         0\n",
            "Ambient Pressure       0\n",
            "Relative Humidity      0\n",
            "Energy Output          0\n",
            "dtype: int64\n",
            "\n",
            "Number of duplicate rows: 41\n",
            "There are duplicate rows in the dataset.\n",
            "Number of rows and columns: (9569, 5)\n",
            "\n",
            "Summary of the dataset:\n",
            "       Ambient Temperature  Exhaust Vaccum  Ambient Pressure  \\\n",
            "count          9569.000000     9569.000000       9569.000000   \n",
            "mean             19.651231       54.305804       1013.259078   \n",
            "std               7.452084       12.707229          5.938473   \n",
            "min               1.810000       25.360000        992.890000   \n",
            "25%              13.510000       41.740000       1009.100000   \n",
            "50%              20.340000       52.080000       1012.940000   \n",
            "75%              25.720000       66.540000       1017.260000   \n",
            "max              37.110000       81.560000       1033.300000   \n",
            "\n",
            "       Relative Humidity  Energy Output  \n",
            "count        9569.000000    9569.000000  \n",
            "mean           73.308978     454.365009  \n",
            "std            14.599506      17.066103  \n",
            "min            25.560000     420.260000  \n",
            "25%            63.330000     439.750000  \n",
            "50%            74.970000     451.580000  \n",
            "75%            84.830000     468.430000  \n",
            "max           100.160000     495.760000  \n",
            "\n",
            "Checking for null values:\n",
            "Ambient Temperature    0\n",
            "Exhaust Vaccum         0\n",
            "Ambient Pressure       0\n",
            "Relative Humidity      0\n",
            "Energy Output          0\n",
            "dtype: int64\n",
            "\n",
            "Number of duplicate rows: 41\n",
            "There are duplicate rows in the dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loaded-arbitration"
      },
      "source": [
        "#### Exercise 4: Scale the data (1 point)\n",
        "\n",
        "Write a function that takes the data after handling the missing data as input and returns the standardized data.\n",
        "\n",
        "**Hint:**\n",
        "\n",
        "- standardization of the data  can be performed using the below formula\n",
        "\n",
        "$ (x - mean(x)) / std(x) $"
      ],
      "id": "loaded-arbitration"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "extraordinary-qatar",
        "scrolled": true
      },
      "source": [
        "# Defining a function to standardize the data\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "id": "extraordinary-qatar",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize_data(data):\n",
        "    \"\"\"\n",
        "    This function takes a pandas DataFrame as input and returns the standardized data.\n",
        "    The standardization is performed using the formula: (x - mean(x)) / std(x).\n",
        "\n",
        "    Parameters:\n",
        "    data (pandas.DataFrame): The input DataFrame to standardize.\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: A DataFrame with standardized data.\n",
        "    \"\"\"\n",
        "    # Standardizing the data\n",
        "    standardized_data = (data - data.mean()) / data.std()\n",
        "\n",
        "    return standardized_data\n"
      ],
      "metadata": {
        "id": "sJ_k-Wwf87Fj"
      },
      "id": "sJ_k-Wwf87Fj",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "FILENAME = \"/content/PowerPlantData.csv\"  # Update this path if needed\n",
        "data = load_data(FILENAME)\n",
        "\n",
        "# Handle missing data\n",
        "data = handle_missing_data(data, method='mean')\n",
        "\n",
        "# Standardize the data\n",
        "standardized_data = standardize_data(data)\n",
        "\n",
        "# Display the first few rows of the standardized data\n",
        "print(standardized_data.head())\n"
      ],
      "metadata": {
        "id": "fWgfvM548-tU",
        "outputId": "1bea1416-912c-44f9-9d69-b2daf1db2380",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fWgfvM548-tU",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Ambient Temperature  Exhaust Vaccum  Ambient Pressure  Relative Humidity  \\\n",
            "0        -4.767410e-16    5.591642e-16     -1.914412e-14           0.000000   \n",
            "1        -1.517862e+00   -1.065205e+00     -4.073569e-01           1.143944   \n",
            "2         5.352555e-01    3.292768e-01     -3.130566e-01           0.061031   \n",
            "3         1.353818e+00    2.041512e-01     -1.028729e+00          -2.150688   \n",
            "4        -7.799579e-02   -3.632424e-01     -1.016941e+00           0.238434   \n",
            "\n",
            "   Energy Output  \n",
            "0       0.000000  \n",
            "1       1.530226  \n",
            "2      -0.504802  \n",
            "3      -0.914386  \n",
            "4      -0.074710  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thermal-rehabilitation"
      },
      "source": [
        "#### Exercise 5: Feature selection (1 point)\n",
        "\n",
        "Write a function that takes scaled data as input and returns the features and target variable values\n",
        "\n",
        "**Hint:**\n",
        "\n",
        "- Features: AmbientTemperature, ExhaustVaccum, AmbientPressure, RelativeHumidity\n",
        "- Target Variable: EnergyOutput"
      ],
      "id": "thermal-rehabilitation"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "terminal-starter",
        "scrolled": true
      },
      "source": [
        "# Define a function\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "id": "terminal-starter",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_selection(data):\n",
        "    \"\"\"\n",
        "    This function takes the standardized data as input and returns the features and target variable values.\n",
        "\n",
        "    Parameters:\n",
        "    data (pandas.DataFrame): The input DataFrame containing the standardized data.\n",
        "\n",
        "    Returns:\n",
        "    X (pandas.DataFrame): The DataFrame containing the feature variables.\n",
        "    y (pandas.Series): The Series containing the target variable.\n",
        "    \"\"\"\n",
        "    # Selecting the features\n",
        "    X = data[['Ambient Temperature', 'Exhaust Vaccum', 'Ambient Pressure', 'Relative Humidity']]\n",
        "\n",
        "    # Selecting the target variable\n",
        "    y = data['Energy Output']\n",
        "\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "VVaa7hmC9Cik"
      },
      "id": "VVaa7hmC9Cik",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "FILENAME = \"/content/PowerPlantData.csv\"  # Update this path if needed\n",
        "data = load_data(FILENAME)\n",
        "\n",
        "# Handle missing data\n",
        "data = handle_missing_data(data, method='mean')\n",
        "\n",
        "# Standardize the data\n",
        "standardized_data = standardize_data(data)\n",
        "\n",
        "# Perform feature selection\n",
        "X, y = feature_selection(standardized_data)\n",
        "\n",
        "# Display the first few rows of features and target variable\n",
        "print(X.head(), y.head())\n"
      ],
      "metadata": {
        "id": "NbvRcDBF9HSj",
        "outputId": "edf6ed46-1919-4300-9973-9885a409cadb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NbvRcDBF9HSj",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Ambient Temperature  Exhaust Vaccum  Ambient Pressure  Relative Humidity\n",
            "0        -4.767410e-16    5.591642e-16     -1.914412e-14           0.000000\n",
            "1        -1.517862e+00   -1.065205e+00     -4.073569e-01           1.143944\n",
            "2         5.352555e-01    3.292768e-01     -3.130566e-01           0.061031\n",
            "3         1.353818e+00    2.041512e-01     -1.028729e+00          -2.150688\n",
            "4        -7.799579e-02   -3.632424e-01     -1.016941e+00           0.238434 0    0.000000\n",
            "1    1.530226\n",
            "2   -0.504802\n",
            "3   -0.914386\n",
            "4   -0.074710\n",
            "Name: Energy Output, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "timely-bruce"
      },
      "source": [
        "#### Exercise 6: Correlation (1 point)\n",
        "\n",
        "Calculate correlation between the variables"
      ],
      "id": "timely-bruce"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "durable-making",
        "scrolled": true
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "durable-making",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_correlation(data):\n",
        "    \"\"\"\n",
        "    This function takes a pandas DataFrame as input and calculates the correlation between variables.\n",
        "\n",
        "    Parameters:\n",
        "    data (pandas.DataFrame): The input DataFrame containing the standardized data.\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: A DataFrame showing the correlation matrix of the variables.\n",
        "    \"\"\"\n",
        "    # Calculate the correlation matrix\n",
        "    correlation_matrix = data.corr()\n",
        "\n",
        "    return correlation_matrix\n"
      ],
      "metadata": {
        "id": "0aqXGY109LOE"
      },
      "id": "0aqXGY109LOE",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "FILENAME = \"/content/PowerPlantData.csv\"  # Update this path if needed\n",
        "data = load_data(FILENAME)\n",
        "\n",
        "# Handle missing data\n",
        "data = handle_missing_data(data, method='mean')\n",
        "\n",
        "# Standardize the data\n",
        "standardized_data = standardize_data(data)\n",
        "\n",
        "# Calculate correlation\n",
        "correlation_matrix = calculate_correlation(standardized_data)\n",
        "\n",
        "# Display the correlation matrix\n",
        "print(correlation_matrix)\n"
      ],
      "metadata": {
        "id": "f6rwKHKJ9ON0",
        "outputId": "a66fc1fc-c61b-4137-80e1-f4b544ff654f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "f6rwKHKJ9ON0",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Ambient Temperature  Exhaust Vaccum  Ambient Pressure  \\\n",
            "Ambient Temperature             1.000000        0.844107         -0.507549   \n",
            "Exhaust Vaccum                  0.844107        1.000000         -0.413502   \n",
            "Ambient Pressure               -0.507549       -0.413502          1.000000   \n",
            "Relative Humidity              -0.542535       -0.312187          0.099574   \n",
            "Energy Output                  -0.948128       -0.869780          0.518429   \n",
            "\n",
            "                     Relative Humidity  Energy Output  \n",
            "Ambient Temperature          -0.542535      -0.948128  \n",
            "Exhaust Vaccum               -0.312187      -0.869780  \n",
            "Ambient Pressure              0.099574       0.518429  \n",
            "Relative Humidity             1.000000       0.389794  \n",
            "Energy Output                 0.389794       1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "honest-remainder"
      },
      "source": [
        "#### Exercise 7: Estimate the coefficients (2 points)\n",
        "\n",
        "Write a function that takes features and target as input and returns the estimated coefficient values\n",
        "\n",
        "**Hint:**\n",
        "\n",
        "- Calculate the estimated coefficients using the below formula\n",
        "\n",
        "$ β = (X^T X)^{-1} X^T y $\n",
        "\n",
        "- transpose(), np.linalg.inv()"
      ],
      "id": "honest-remainder"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dimensional-victory",
        "scrolled": true
      },
      "source": [
        "# Calculating the coeffients\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "id": "dimensional-victory",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def estimate_coefficients(X, y):\n",
        "    \"\"\"\n",
        "    This function takes the features and target as input and returns the estimated coefficient values.\n",
        "\n",
        "    Parameters:\n",
        "    X (pandas.DataFrame): The input DataFrame containing the feature variables.\n",
        "    y (pandas.Series): The input Series containing the target variable.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: An array of estimated coefficient values.\n",
        "    \"\"\"\n",
        "    # Add a column of ones to X for the intercept term\n",
        "    X_with_intercept = np.c_[np.ones(X.shape[0]), X]\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_np = np.array(X_with_intercept)\n",
        "    y_np = np.array(y).reshape(-1, 1)\n",
        "\n",
        "    # Calculate the coefficients using the formula β=(XTX)−1XTy\n",
        "    X_transpose_X = np.dot(X_np.T, X_np)\n",
        "    X_transpose_X_inv = np.linalg.inv(X_transpose_X)\n",
        "    X_transpose_y = np.dot(X_np.T, y_np)\n",
        "\n",
        "    coefficients = np.dot(X_transpose_X_inv, X_transpose_y)\n",
        "\n",
        "    return coefficients.flatten()\n"
      ],
      "metadata": {
        "id": "lhvWvuju9Vt7"
      },
      "id": "lhvWvuju9Vt7",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "FILENAME = \"/content/PowerPlantData.csv\"  # Update this path if needed\n",
        "data = load_data(FILENAME)\n",
        "\n",
        "# Handle missing data\n",
        "data = handle_missing_data(data, method='mean')\n",
        "\n",
        "# Standardize the data\n",
        "standardized_data = standardize_data(data)\n",
        "\n",
        "# Perform feature selection\n",
        "X, y = feature_selection(standardized_data)\n",
        "\n",
        "# Estimate the coefficients\n",
        "coefficients = estimate_coefficients(X, y)\n",
        "\n",
        "# Display the estimated coefficients\n",
        "print(\"Estimated Coefficients:\", coefficients)\n"
      ],
      "metadata": {
        "id": "k-U7ZS-A9XLk",
        "outputId": "23a2024b-21d8-4946-938d-50a138711aa8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "k-U7ZS-A9XLk",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated Coefficients: [-1.49677674e-15 -8.63500780e-01 -1.74171544e-01  2.16029345e-02\n",
            " -1.35210234e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "interior-bennett"
      },
      "source": [
        "#### Exercise 8: Fit the data to estimate the coefficients (2 points)\n",
        "\n",
        "Write a function named fit which takes features and targets as input and returns the intercept and coefficient values.\n",
        "\n",
        "**Hint:**\n",
        "\n",
        "- create a dummy column in the features dataframe which is made up of all ones\n",
        "- convert the features dataframe into numpy array\n",
        "- call the estimated coefficients function which is defined above\n",
        "- np.ones(), np.concatenate()"
      ],
      "id": "interior-bennett"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "local-texas",
        "scrolled": true,
        "outputId": "54afd958-9c27-49b8-fc30-11d21ab6a39a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "# defining a fit function\n",
        "def fit(x, y):\n",
        "    # YOUR CODE HERE"
      ],
      "id": "local-texas",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-24-066be1772e5a>, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-066be1772e5a>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    # YOUR CODE HERE\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def fit(X, y):\n",
        "    \"\"\"\n",
        "    This function takes the features and target as input and returns the intercept and coefficient values\n",
        "    for a linear regression model.\n",
        "\n",
        "    Parameters:\n",
        "    X (pandas.DataFrame or numpy.ndarray): The input DataFrame or array containing the feature variables.\n",
        "    y (pandas.Series or numpy.ndarray): The input Series or array containing the target variable.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the intercept and an array of coefficients.\n",
        "    \"\"\"\n",
        "    # Add a column of ones to X for the intercept term\n",
        "    X_with_intercept = np.c_[np.ones(X.shape[0]), X]\n",
        "\n",
        "    # Convert to numpy arrays if needed\n",
        "    X_np = np.array(X_with_intercept)\n",
        "    y_np = np.array(y).reshape(-1, 1)\n",
        "\n",
        "    # Estimate coefficients using the formula β=(X^T X)−1 X^T y\n",
        "    X_transpose_X = np.dot(X_np.T, X_np)\n",
        "    X_transpose_X_inv = np.linalg.inv(X_transpose_X)\n",
        "    X_transpose_y = np.dot(X_np.T, y_np)\n",
        "\n",
        "    coefficients = np.dot(X_transpose_X_inv, X_transpose_y)\n",
        "\n",
        "    # The first coefficient is the intercept\n",
        "    intercept = coefficients[0]\n",
        "\n",
        "    # The remaining coefficients are for the features\n",
        "    feature_coefficients = coefficients[1:].flatten()\n",
        "\n",
        "    return intercept[0], feature_coefficients\n",
        "\n",
        "# Example usage (assuming you have standardized data and selected features):\n",
        "# intercept, coefficients = fit(X, y)\n",
        "# print(\"Intercept:\", intercept)\n",
        "# print(\"Coefficients:\", coefficients)\n"
      ],
      "metadata": {
        "id": "_h8oTFzX_k4j"
      },
      "id": "_h8oTFzX_k4j",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hybrid-quick"
      },
      "source": [
        "#### Exercise 9: Predict the data on estimated coefficients (1 point)\n",
        "\n",
        "Write a function named predict which takes features, intercept and coefficient values as input and returns the predicted values.\n",
        "\n",
        "**Hint:**\n",
        "\n",
        "- Fit the intercept, coefficients values in the below equation\n",
        "\n",
        "  $y = b_0 + b_1*x + ... + b_i*x_i$"
      ],
      "id": "hybrid-quick"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buried-attention",
        "scrolled": true
      },
      "source": [
        " # fucntion to predict the values\n",
        "def predict(x, intercept, coefficients):\n",
        "    '''\n",
        "    y = b_0 + b_1*x + ... + b_i*x_i\n",
        "    '''\n",
        "    #YOUR CODE HERE\n",
        "\n",
        "    return predictions"
      ],
      "id": "buried-attention",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def predict(X, intercept, coefficients):\n",
        "    \"\"\"\n",
        "    This function predicts the target values for the given input features using the provided intercept and coefficients.\n",
        "\n",
        "    Parameters:\n",
        "    X (pandas.DataFrame or numpy.ndarray): The input DataFrame or array containing the feature variables.\n",
        "    intercept (float): The intercept value of the regression model.\n",
        "    coefficients (numpy.ndarray): The array of coefficient values for the regression model.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: An array of predicted values.\n",
        "    \"\"\"\n",
        "    # Convert X to numpy array if it's a DataFrame\n",
        "    if isinstance(X, pd.DataFrame):\n",
        "        X = X.values\n",
        "\n",
        "    # Calculate predictions using the formula: y = intercept + (coefficients * X)\n",
        "    predictions = intercept + np.dot(X, coefficients)\n",
        "\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "o6aBPfnHAbP8"
      },
      "id": "o6aBPfnHAbP8",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Loading the data.\n",
        "2. Handling missing data.\n",
        "3. Standardizing the data.\n",
        "4. Performing feature selection.\n",
        "5. Splitting the data into training and test sets."
      ],
      "metadata": {
        "id": "F5EURfNUAr8V"
      },
      "id": "F5EURfNUAr8V"
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_missing_data(data, method='mean'):\n",
        "    # Convert all columns to numeric, forcing non-numeric values to NaN\n",
        "    data = data.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    if method == 'mean':\n",
        "        # Replace missing values with column means\n",
        "        return data.fillna(data.mean())\n",
        "    elif method == 'drop':\n",
        "        # Drop rows with missing values\n",
        "        return data.dropna()\n",
        "    else:\n",
        "        raise ValueError(\"Invalid method. Use 'mean' or 'drop'.\")\n"
      ],
      "metadata": {
        "id": "r7EsLpGBBLi7"
      },
      "id": "r7EsLpGBBLi7",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def train_test_split(X, y, test_size=0.3, random_state=42):\n",
        "    \"\"\"\n",
        "    Split the dataset into training and test sets.\n",
        "\n",
        "    Parameters:\n",
        "    X (pandas.DataFrame or numpy.ndarray): Feature variables.\n",
        "    y (pandas.Series or numpy.ndarray): Target variable.\n",
        "    test_size (float): Proportion of the dataset to include in the test split.\n",
        "    random_state (int): Seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "    X_train, X_test, y_train, y_test: Split datasets.\n",
        "    \"\"\"\n",
        "    # Set random seed for reproducibility\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Convert to NumPy arrays if they're pandas DataFrame or Series\n",
        "    if isinstance(X, pd.DataFrame):\n",
        "        X = X.values\n",
        "    if isinstance(y, pd.Series):\n",
        "        y = y.values\n",
        "\n",
        "    # Concatenate X and y to shuffle them together\n",
        "    data = np.concatenate((X, y.reshape(-1, 1)), axis=1)\n",
        "\n",
        "    # Shuffle the data\n",
        "    np.random.shuffle(data)\n",
        "\n",
        "    # Split the data into training and test sets\n",
        "    split_index = int((1 - test_size) * len(data))\n",
        "    train_data = data[:split_index]\n",
        "    test_data = data[split_index:]\n",
        "\n",
        "    # Separate features and target\n",
        "    X_train, y_train = train_data[:, :-1], train_data[:, -1]\n",
        "    X_test, y_test = test_data[:, :-1], test_data[:, -1]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "uI3nh0cGBei0"
      },
      "id": "uI3nh0cGBei0",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "FILENAME = \"/content/PowerPlantData.csv\"  # Ensure the file path is correct\n",
        "data = load_data(FILENAME)\n",
        "\n",
        "# Clean and handle missing data\n",
        "data = handle_missing_data(data, method='mean')\n",
        "\n",
        "# Standardize the data\n",
        "standardized_data = standardize_data(data)\n",
        "\n",
        "# Perform feature selection\n",
        "X, y = feature_selection(standardized_data)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# Fit the model to estimate coefficients\n",
        "intercept, coefficients = fit(X_train, y_train)\n",
        "\n",
        "# Predict using test data\n",
        "predicted_values = predict(X_test, intercept, coefficients)\n",
        "\n",
        "# Display the first few predicted values\n",
        "print(predicted_values[:5])\n"
      ],
      "metadata": {
        "id": "-oG0Vb-fBUcr",
        "outputId": "f9fffe9c-b091-4492-e5ad-9aab1dd5b53c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-oG0Vb-fBUcr",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.50300231 -1.11995819 -1.20769725 -0.20023076 -1.20770031]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rolled-consultancy"
      },
      "source": [
        "#### Exercise 10: Root mean squared error (1 point)\n",
        "\n",
        "Write a function to calculate the RMSE error.\n",
        "\n",
        "**Hint:**\n",
        "\n",
        "- [How to calculate the RSME error](https://towardsdatascience.com/what-does-rmse-really-mean-806b65f2e48e)"
      ],
      "id": "rolled-consultancy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phantom-alabama",
        "scrolled": true
      },
      "source": [
        "# Define a function to calculate the error\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "id": "phantom-alabama",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_rmse(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the Root Mean Squared Error (RMSE) between the actual and predicted values.\n",
        "\n",
        "    Parameters:\n",
        "    y_true (numpy.ndarray or pandas.Series): The actual target values.\n",
        "    y_pred (numpy.ndarray or pandas.Series): The predicted target values.\n",
        "\n",
        "    Returns:\n",
        "    float: The calculated RMSE value.\n",
        "    \"\"\"\n",
        "    # Convert to numpy arrays if inputs are pandas Series\n",
        "    if isinstance(y_true, pd.Series):\n",
        "        y_true = y_true.values\n",
        "    if isinstance(y_pred, pd.Series):\n",
        "        y_pred = y_pred.values\n",
        "\n",
        "    # Calculate RMSE using the formula: sqrt(mean((y_true - y_pred)^2))\n",
        "    rmse = np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
        "\n",
        "    return rmse\n"
      ],
      "metadata": {
        "id": "t3HdjmOnB4Oj"
      },
      "id": "t3HdjmOnB4Oj",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume you have already made predictions with your test data\n",
        "# predicted_values = predict(X_test, intercept, coefficients)\n",
        "\n",
        "# Now, calculate the RMSE\n",
        "rmse = calculate_rmse(y_test, predicted_values)\n",
        "\n",
        "# Display the RMSE\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n"
      ],
      "metadata": {
        "id": "uGASYubjBxPr",
        "outputId": "50361849-db99-455e-aa90-ea64e7250a5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "uGASYubjBxPr",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 0.2693686279036376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "experimental-discrimination"
      },
      "source": [
        "#### Exercise 11: Split the data into train and test (1 point)\n",
        "\n",
        "Write a function named train_test_split which takes features and targets as input and returns the train and test sets respectively.\n",
        "\n",
        "**Hint:**\n",
        "\n",
        "- Shuffle the data\n",
        "- Consider 70 % of data as a train set and the rest of the data as a test set"
      ],
      "id": "experimental-discrimination"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dangerous-salmon",
        "scrolled": true
      },
      "source": [
        "    # YOUR CODE HERE"
      ],
      "id": "dangerous-salmon",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming X and y are already defined (from feature selection)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Print the sizes of the training and testing sets\n",
        "print(\"Training set size:\", len(X_train))\n",
        "print(\"Test set size:\", len(X_test))\n"
      ],
      "metadata": {
        "id": "Kc4YyY9mCFJU",
        "outputId": "31625cbe-f83b-4676-ad05-3157d7173075",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Kc4YyY9mCFJU",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 6698\n",
            "Test set size: 2871\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "living-operation"
      },
      "source": [
        "#### Exercise 12: Implement predict using OpenMP (1 point)\n",
        "\n",
        "Get the predictions for test data and calculate the test error(RMSE) by implementing the OpenMP (pymp)\n",
        "\n",
        "**Hints:**\n",
        "\n",
        "* Using the pymp.Parallel implement the predict function (use from above)\n",
        "\n",
        "* Call the predict function by passing test data as an argument\n",
        "\n",
        "* calculate the error (RMSE) by comparing the Actual test data and predicted test data"
      ],
      "id": "living-operation"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymp-pypi"
      ],
      "metadata": {
        "id": "1PndfF9b_mkN",
        "outputId": "79483a87-4fc1-4205-e5df-f40ae00c54eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "1PndfF9b_mkN",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymp-pypi\n",
            "  Downloading pymp-pypi-0.5.0.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pymp-pypi\n",
            "  Building wheel for pymp-pypi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymp-pypi: filename=pymp_pypi-0.5.0-py3-none-any.whl size=10314 sha256=589a3f89320c0e0bf6b6357baf74fe3f0d67259c53fa5f4ed93f4db658cb79ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/db/4b/4c02f5b91b1abcde14433d1b336ac00a09761383e7bb1013cf\n",
            "Successfully built pymp-pypi\n",
            "Installing collected packages: pymp-pypi\n",
            "Successfully installed pymp-pypi-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymp\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "o8DSppnV_wQa"
      },
      "id": "o8DSppnV_wQa",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pymp  # Ensure that pymp is installed in your environment\n",
        "\n",
        "def parallel_predict(X, intercept, coefficients, num_threads=4):\n",
        "    \"\"\"\n",
        "    This function predicts values for input features using parallel processing with pymp.\n",
        "    \"\"\"\n",
        "    predictions = pymp.shared.array((X.shape[0],), dtype='float')\n",
        "\n",
        "    with pymp.Parallel(num_threads) as p:\n",
        "        for i in p.range(X.shape[0]):\n",
        "            predictions[i] = intercept + np.dot(X[i], coefficients)\n",
        "\n",
        "    return np.array(predictions)\n",
        "\n",
        "def calculate_rmse(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the Root Mean Squared Error (RMSE) between actual and predicted values.\n",
        "    \"\"\"\n",
        "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n"
      ],
      "metadata": {
        "id": "QW4AtG6NC8-r"
      },
      "id": "QW4AtG6NC8-r",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have your X_train, X_test, y_train, and y_test ready\n",
        "\n",
        "# Fit your model to get intercept and coefficients\n",
        "intercept, coefficients = fit(X_train, y_train)  # Ensure the fit function is defined\n",
        "\n",
        "# Predict using the parallel_predict function\n",
        "predicted_test_values = parallel_predict(X_test, intercept, coefficients, num_threads=4)\n",
        "\n",
        "# Calculate the RMSE for the test set\n",
        "rmse = calculate_rmse(y_test, predicted_test_values)\n",
        "\n",
        "# Display the RMSE\n",
        "print(\"Test RMSE using parallel prediction:\", rmse)\n"
      ],
      "metadata": {
        "id": "p8T4mcpqC_Sj",
        "outputId": "bf27e657-42c5-4279-d459-50a72c595a0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "p8T4mcpqC_Sj",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSE using parallel prediction: 0.2693686279036376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "covered-canon"
      },
      "source": [
        "#### Exercise 13: Create a communicator (1 point)\n",
        "\n",
        "Create a comunicator and define the rank and size"
      ],
      "id": "covered-canon"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "radio-origin",
        "scrolled": true
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "radio-origin",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y mpich\n",
        "!pip install mpi4py\n",
        "\n"
      ],
      "metadata": {
        "id": "bNVemI2hD7Hq",
        "outputId": "7dc408d5-0695-4db4-92aa-fc86b69fb18d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bNVemI2hD7Hq",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  hwloc-nox libmpich-dev libmpich12 libslurm37\n",
            "Suggested packages:\n",
            "  mpich-doc\n",
            "The following NEW packages will be installed:\n",
            "  hwloc-nox libmpich-dev libmpich12 libslurm37 mpich\n",
            "0 upgraded, 5 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 14.2 MB of archives.\n",
            "After this operation, 102 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libslurm37 amd64 21.08.5-2ubuntu1 [542 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 hwloc-nox amd64 2.7.0-2ubuntu1 [205 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmpich12 amd64 4.0-3 [5,866 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 mpich amd64 4.0-3 [197 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmpich-dev amd64 4.0-3 [7,375 kB]\n",
            "Fetched 14.2 MB in 1s (22.4 MB/s)\n",
            "Selecting previously unselected package libslurm37.\n",
            "(Reading database ... 123599 files and directories currently installed.)\n",
            "Preparing to unpack .../libslurm37_21.08.5-2ubuntu1_amd64.deb ...\n",
            "Unpacking libslurm37 (21.08.5-2ubuntu1) ...\n",
            "Selecting previously unselected package hwloc-nox.\n",
            "Preparing to unpack .../hwloc-nox_2.7.0-2ubuntu1_amd64.deb ...\n",
            "Unpacking hwloc-nox (2.7.0-2ubuntu1) ...\n",
            "Selecting previously unselected package libmpich12:amd64.\n",
            "Preparing to unpack .../libmpich12_4.0-3_amd64.deb ...\n",
            "Unpacking libmpich12:amd64 (4.0-3) ...\n",
            "Selecting previously unselected package mpich.\n",
            "Preparing to unpack .../archives/mpich_4.0-3_amd64.deb ...\n",
            "Unpacking mpich (4.0-3) ...\n",
            "Selecting previously unselected package libmpich-dev:amd64.\n",
            "Preparing to unpack .../libmpich-dev_4.0-3_amd64.deb ...\n",
            "Unpacking libmpich-dev:amd64 (4.0-3) ...\n",
            "Setting up libslurm37 (21.08.5-2ubuntu1) ...\n",
            "Setting up hwloc-nox (2.7.0-2ubuntu1) ...\n",
            "Setting up libmpich12:amd64 (4.0-3) ...\n",
            "Setting up mpich (4.0-3) ...\n",
            "Setting up libmpich-dev:amd64 (4.0-3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: mpi4py in /usr/local/lib/python3.10/dist-packages (4.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mpi4py import MPI\n",
        "\n",
        "# Create a communicator\n",
        "comm = MPI.COMM_WORLD\n",
        "\n",
        "# Get the rank of the current process\n",
        "rank = comm.Get_rank()\n",
        "\n",
        "# Get the total number of processes in the communicator\n",
        "size = comm.Get_size()\n",
        "\n",
        "# Output the rank and size for this process\n",
        "print(f\"Process rank: {rank}, Total number of processes: {size}\")\n"
      ],
      "metadata": {
        "id": "NHnX2927ER-T",
        "outputId": "b2fb8d8d-4634-4f63-9b4b-cc9cbf18a966",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NHnX2927ER-T",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process rank: 0, Total number of processes: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternative"
      ],
      "metadata": {
        "id": "yQXB5bJqEa7D"
      },
      "id": "yQXB5bJqEa7D"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymp-pypi\n"
      ],
      "metadata": {
        "id": "Cl6xdIFuEbnL",
        "outputId": "374f3339-0b3b-433d-b581-5bcc4f71ed4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Cl6xdIFuEbnL",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymp-pypi in /usr/local/lib/python3.10/dist-packages (0.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymp\n",
        "\n",
        "# Parallel execution using pymp\n",
        "with pymp.Parallel(4) as p:\n",
        "    for i in p.range(10):\n",
        "        print(f\"Hello from thread {p.thread_num}, iteration {i}\")\n"
      ],
      "metadata": {
        "id": "wz0aYYtrEeJL",
        "outputId": "2d1c641b-3942-4b4e-d3f4-91ecb6283343",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wz0aYYtrEeJL",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from thread 1, iteration 3\n",
            "Hello from thread 1, iteration 4\n",
            "Hello from thread 2, iteration 6Hello from thread 3, iteration 8\n",
            "Hello from thread 2, iteration 7\n",
            "Hello from thread 1, iteration 5\n",
            "\n",
            "Hello from thread 3, iteration 9\n",
            "Hello from thread 0, iteration 0\n",
            "Hello from thread 0, iteration 1\n",
            "Hello from thread 0, iteration 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miniature-plaza"
      },
      "source": [
        "#### Exercise 14: Divide the data into slices (1 point)\n",
        "\n",
        "Write a function named dividing_data which takes train features set, train target set, and size of workers as inputs and returns the sliced data for each worker.\n",
        "\n",
        "![img](https://cdn.iisc.talentsprint.com/CDS/Images/MiniProject_MPI_DataSlice.JPG)\n",
        "\n",
        "For Example, if there are 4 processes, slice the data into 4 equal parts with 25% ratio\n",
        "\n",
        "**Hint:**\n",
        "\n",
        "- Divide the Data equally among the workers\n",
        "  - Create an empty list\n",
        "  - Iterate over the size of workers\n",
        "  - Append each slice of data to the list"
      ],
      "id": "miniature-plaza"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "signal-medicaid",
        "scrolled": true
      },
      "source": [
        "def dividing_data(x_train, y_train, size_of_workers):\n",
        "    # Size of the slice\n",
        "    slice_for_each_worker = int(Decimal(x_train.shape[0]/size_of_workers).quantize(Decimal('1.'), rounding = ROUND_HALF_UP))\n",
        "    print('Slice of data for each worker: {}'.format(slice_for_each_worker))\n",
        "    # YOUR CODE HERE"
      ],
      "id": "signal-medicaid",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from decimal import Decimal, ROUND_HALF_UP\n",
        "\n",
        "def dividing_data(x_train, y_train, size_of_workers):\n",
        "    # Size of the slice\n",
        "    slice_for_each_worker = int(Decimal(x_train.shape[0] / size_of_workers).quantize(Decimal('1.'), rounding=ROUND_HALF_UP))\n",
        "\n",
        "    print('Slice of data for each worker: {}'.format(slice_for_each_worker))\n",
        "\n",
        "    # Create a list to hold the data slices for each worker\n",
        "    data_slices = []\n",
        "\n",
        "    # Iterate over the number of workers and create slices\n",
        "    for worker in range(size_of_workers):\n",
        "        start_index = worker * slice_for_each_worker\n",
        "        end_index = start_index + slice_for_each_worker\n",
        "\n",
        "        # For the last worker, make sure to include any leftover rows\n",
        "        if worker == size_of_workers - 1:\n",
        "            end_index = x_train.shape[0]\n",
        "\n",
        "        # Append the sliced data for each worker\n",
        "        x_slice = x_train[start_index:end_index]\n",
        "        y_slice = y_train[start_index:end_index]\n",
        "\n",
        "        data_slices.append((x_slice, y_slice))\n",
        "\n",
        "    return data_slices\n",
        "\n",
        "# Example usage:\n",
        "# Assuming x_train and y_train are numpy arrays or pandas DataFrames with your training data.\n",
        "# size_of_workers = 4\n",
        "# data_slices = dividing_data(x_train, y_train, size_of_workers)\n",
        "# print(data_slices)\n"
      ],
      "metadata": {
        "id": "Nw7pQlBZE3Tr"
      },
      "id": "Nw7pQlBZE3Tr",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example Workflow:"
      ],
      "metadata": {
        "id": "y3F927WaE-0r"
      },
      "id": "y3F927WaE-0r"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example data\n",
        "x_train = np.array([[1], [2], [3], [4], [5], [6], [7], [8]])\n",
        "y_train = np.array([1, 0, 1, 0, 1, 0, 1, 0])\n",
        "\n",
        "# Divide data for 4 workers\n",
        "size_of_workers = 4\n",
        "data_slices = dividing_data(x_train, y_train, size_of_workers)\n",
        "\n",
        "# Output each worker's data slice\n",
        "for i, (x_slice, y_slice) in enumerate(data_slices):\n",
        "    print(f\"Worker {i+1} slice:\")\n",
        "    print(\"x_slice:\", x_slice)\n",
        "    print(\"y_slice:\", y_slice)\n"
      ],
      "metadata": {
        "id": "g81DPw6rE77j",
        "outputId": "56db7d7d-fb88-43d2-c47f-6197347c7f3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "g81DPw6rE77j",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slice of data for each worker: 2\n",
            "Worker 1 slice:\n",
            "x_slice: [[1]\n",
            " [2]]\n",
            "y_slice: [1 0]\n",
            "Worker 2 slice:\n",
            "x_slice: [[3]\n",
            " [4]]\n",
            "y_slice: [1 0]\n",
            "Worker 3 slice:\n",
            "x_slice: [[5]\n",
            " [6]]\n",
            "y_slice: [1 0]\n",
            "Worker 4 slice:\n",
            "x_slice: [[7]\n",
            " [8]]\n",
            "y_slice: [1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MPI"
      ],
      "metadata": {
        "id": "tkGji1eh7YM4"
      },
      "id": "tkGji1eh7YM4"
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq mpich\n",
        "!pip install mpi4py\n"
      ],
      "metadata": {
        "id": "ZX1OUEsR7cn6",
        "outputId": "5c3658de-4f2f-4d1e-d1ff-f645bdb88ba4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ZX1OUEsR7cn6",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mpi4py in /usr/local/lib/python3.10/dist-packages (4.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpirun --version\n"
      ],
      "metadata": {
        "id": "kdQy_qib7hNi",
        "outputId": "08fd666f-8b28-4f3d-dfde-63b2ea2dbc88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kdQy_qib7hNi",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mpirun (Open MPI) 4.1.2\n",
            "\n",
            "Report bugs to http://www.open-mpi.org/community/help/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sample code for MPI"
      ],
      "metadata": {
        "id": "VOprMRTX90TD"
      },
      "id": "VOprMRTX90TD"
    },
    {
      "cell_type": "code",
      "source": [
        "code = \"\"\"\n",
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "size = comm.Get_size()\n",
        "\n",
        "# Only the root process (rank 0) will create and scatter the data\n",
        "if rank == 0:\n",
        "    data = np.linspace(0, 100, size)\n",
        "    print(f\"Root process is scattering data: {data}\")\n",
        "else:\n",
        "    data = None\n",
        "\n",
        "# Scatter the data to all processes\n",
        "data = comm.scatter(data, root=0)\n",
        "print(f\"Process {rank} received data: {data}\")\n",
        "\n",
        "# Each process computes the square of the data it received\n",
        "result = data ** 2\n",
        "\n",
        "# Gather the results at the root process\n",
        "results = comm.gather(result, root=0)\n",
        "\n",
        "# The root process prints the gathered results\n",
        "if rank == 0:\n",
        "    print(f\"Root process gathered results: {results}\")\n",
        "\"\"\"\n",
        "\n",
        "with open(\"mpi_test.py\", \"w\") as f:\n",
        "    f.write(code)\n"
      ],
      "metadata": {
        "id": "J-M5rtoe7kSD"
      },
      "id": "J-M5rtoe7kSD",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mpirun --allow-run-as-root --oversubscribe -np 4 python mpi_test.py\n"
      ],
      "metadata": {
        "id": "rScakf6L7qul"
      },
      "id": "rScakf6L7qul",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "another sample code for MPI"
      ],
      "metadata": {
        "id": "g0dLoD829wxL"
      },
      "id": "g0dLoD829wxL"
    },
    {
      "cell_type": "code",
      "source": [
        "# Save this simple MPI test script\n",
        "test_code = \"\"\"\n",
        "from mpi4py import MPI\n",
        "\n",
        "comm = MPI.COMM_WORLD\n",
        "rank = comm.Get_rank()\n",
        "size = comm.Get_size()\n",
        "\n",
        "print(f\"Process {rank} out of {size} processes is running.\")\n",
        "\"\"\"\n",
        "\n",
        "with open(\"mpi_test.py\", \"w\") as f:\n",
        "    f.write(test_code)\n"
      ],
      "metadata": {
        "id": "pb_fgeDH9j6s"
      },
      "id": "pb_fgeDH9j6s",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mpirun --allow-run-as-root --oversubscribe -np 4 python mpi_test.py\n"
      ],
      "metadata": {
        "id": "tHpQvIYa9ndE"
      },
      "id": "tHpQvIYa9ndE",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Running required code."
      ],
      "metadata": {
        "id": "Q4sxtPe99tET"
      },
      "id": "Q4sxtPe99tET",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mpirun --allow-run-as-root --oversubscribe -np 4 python mpi_scatter_gather.py\n"
      ],
      "metadata": {
        "id": "AV_dkpiv86aS"
      },
      "id": "AV_dkpiv86aS",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "changing-conditioning"
      },
      "source": [
        "#### Exercise 15: Prepare the data in root worker to assign data for all the workers (1 point)\n",
        "\n",
        "- When it is the root worker, perform the below operation:\n",
        "    - Store the features and target values in separate variables\n",
        "    - Split the data into train and test sets using the train_test_split function defined above\n",
        "    - Divide the data among the workers using the dividing_data function above"
      ],
      "id": "changing-conditioning"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hybrid-tamil",
        "scrolled": true
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "hybrid-tamil",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq mpich\n",
        "!pip install mpi4py\n"
      ],
      "metadata": {
        "id": "8y5WbvvG6wNq",
        "outputId": "0262b5fd-cfc3-4510-ac9e-9cc39374ce91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8y5WbvvG6wNq",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mpi4py in /usr/local/lib/python3.10/dist-packages (4.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Store features and target values in separate variables.\n",
        "2. Split the data into training and test sets using the train_test_split function.\n",
        "3. Divide the data among workers using the dividing_data function.\n",
        "4. Distribute the data using MPI to assign data to all workers.\n"
      ],
      "metadata": {
        "id": "9G0hfPH02eIU"
      },
      "id": "9G0hfPH02eIU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "mpi_data_prep.py file code in below cell."
      ],
      "metadata": {
        "id": "q_AkSbP82tvy"
      },
      "id": "q_AkSbP82tvy"
    },
    {
      "cell_type": "code",
      "source": [
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example function to divide the data for each worker\n",
        "def dividing_data(x_train, y_train, size_of_workers):\n",
        "    slice_size = len(x_train) // size_of_workers\n",
        "    slices = [(x_train[i * slice_size:(i + 1) * slice_size], y_train[i * slice_size:(i + 1) * slice_size])\n",
        "              for i in range(size_of_workers)]\n",
        "    return slices\n",
        "\n",
        "def prepare_data_for_workers(x, y, test_size, size_of_workers):\n",
        "    \"\"\"\n",
        "    Function to prepare data in root worker to assign to all workers.\n",
        "\n",
        "    Parameters:\n",
        "    x (numpy.ndarray or pandas.DataFrame): The input feature data.\n",
        "    y (numpy.ndarray or pandas.Series): The target labels.\n",
        "    test_size (float): Proportion of the dataset to include in the test split.\n",
        "    size_of_workers (int): Number of workers for dividing the data.\n",
        "\n",
        "    Returns:\n",
        "    Tuple containing the training and testing data (features and labels).\n",
        "    \"\"\"\n",
        "\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()\n",
        "\n",
        "    if rank == 0:\n",
        "        # Step 1: Store features and target values in variables\n",
        "        print(\"Root worker: Storing features and target values\")\n",
        "\n",
        "        # Step 2: Split the data into train and test sets\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=42)\n",
        "        print(\"Root worker: Split the data into train and test sets\")\n",
        "\n",
        "        # Step 3: Divide the training data among workers\n",
        "        data_slices = dividing_data(x_train, y_train, size_of_workers)\n",
        "        print(f\"Root worker: Divided the training data into {size_of_workers} slices\")\n",
        "\n",
        "        # Distribute the slices to each worker\n",
        "        for i in range(1, size_of_workers):\n",
        "            comm.send(data_slices[i], dest=i, tag=i)\n",
        "            print(f\"Root worker: Sent data slice {i} to worker {i}\")\n",
        "\n",
        "        return data_slices[0], x_test, y_test  # Root worker keeps the first slice\n",
        "\n",
        "    else:\n",
        "        # Other workers receive their slice of the data\n",
        "        data_slice = comm.recv(source=0, tag=rank)\n",
        "        print(f\"Worker {rank}: Received data slice\")\n",
        "        return data_slice, None, None\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()\n",
        "    size_of_workers = comm.Get_size()\n",
        "\n",
        "    # Assume you have some dataset (x, y)\n",
        "    if rank == 0:\n",
        "        # Example data\n",
        "        x = np.array([[1], [2], [3], [4], [5], [6], [7], [8]])\n",
        "        y = np.array([1, 0, 1, 0, 1, 0, 1, 0])\n",
        "    else:\n",
        "        x = None\n",
        "        y = None\n",
        "\n",
        "    # Prepare the data\n",
        "    train_data, x_test, y_test = prepare_data_for_workers(x, y, test_size=0.3, size_of_workers=size_of_workers)\n",
        "\n",
        "    if rank == 0:\n",
        "        print(\"Root worker has its data slice and test set\")\n",
        "        print(f\"x_test: {x_test}, y_test: {y_test}\")\n",
        "    else:\n",
        "        print(f\"Worker {rank} received its training data slice.\")\n"
      ],
      "metadata": {
        "id": "IDEMMFXy2rXK",
        "outputId": "ec8f8b31-6565-45ee-c8cb-b0024c09934e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IDEMMFXy2rXK",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root worker: Storing features and target values\n",
            "Root worker: Split the data into train and test sets\n",
            "Root worker: Divided the training data into 1 slices\n",
            "Root worker has its data slice and test set\n",
            "x_test: [[2]\n",
            " [6]\n",
            " [1]], y_test: [0 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mpirun --allow-run-as-root --oversubscribe -np 6 mpi_data_prep.py"
      ],
      "metadata": {
        "id": "BdwrI9ir28Fj"
      },
      "id": "BdwrI9ir28Fj",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "breathing-baking"
      },
      "source": [
        "#### Exercise 16: Scatter and gather the data (1 point)\n",
        "\n",
        "Perform the below operations:\n",
        "\n",
        "- Send slices of the training set(the features data X and the expected target data Y) to every worker including the root worker\n",
        "    - **Hint:** scatter()\n",
        "    - use `barrier()` to block workers until all workers in the group reach a Barrier, to scatter from root worker.\n",
        "- Every worker should get the predicted target Y(yhat) for each slice\n",
        "- Get the new coefficient of each instance in a slice\n",
        "    - **Hint:** fit function defined above\n",
        "- Gather the new coefficient from each worker\n",
        "    - **Hint:** gather()\n",
        "    - Take the mean of the gathered coefficients\n",
        "- Calculate the root mean square error for the test set\n",
        "\n",
        "To know more about `scatter`, `gather` and `barrier` click [here](https://nyu-cds.github.io/python-mpi/05-collectives/)"
      ],
      "id": "breathing-baking"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "consistent-union",
        "scrolled": true
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "consistent-union",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Operations:\n",
        "1. Scatter: Distribute data slices (features X and target Y) among all workers.\n",
        "2. Barrier: Ensure all workers have reached a certain point before proceeding.\n",
        "3. Predictions and Fitting: Each worker fits a model to its slice and predicts values (yhat).\n",
        "4. Gather: Gather the computed coefficients from all workers to the root worker.\n",
        "5. Compute Mean of Coefficients: The root worker computes the mean of all coefficients.\n",
        "6. RMSE Calculation: The root worker calculates the RMSE for the test set."
      ],
      "metadata": {
        "id": "16iakPz-4dJa"
      },
      "id": "16iakPz-4dJa"
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE for scipt(.py)\n",
        "\n",
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example fit function that estimates coefficients using linear regression\n",
        "def fit(X, y):\n",
        "    X = np.c_[np.ones(X.shape[0]), X]  # Add intercept term\n",
        "    beta = np.linalg.inv(X.T @ X) @ (X.T @ y)  # Linear regression formula\n",
        "    return beta  # Coefficients including intercept\n",
        "\n",
        "# RMSE calculation function\n",
        "def calculate_rmse(y_true, y_pred):\n",
        "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
        "\n",
        "def scatter_gather_operations(x_train, y_train, x_test, y_test, size_of_workers):\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()\n",
        "\n",
        "    # Step 1: Scatter the training data to all workers\n",
        "    data_slices = None\n",
        "    if rank == 0:\n",
        "        # Prepare slices to scatter\n",
        "        slice_size = len(x_train) // size_of_workers\n",
        "        data_slices = [(x_train[i * slice_size:(i + 1) * slice_size], y_train[i * slice_size:(i + 1) * slice_size])\n",
        "                       for i in range(size_of_workers)]\n",
        "\n",
        "    # Scatter the slices (x_train and y_train) to all workers\n",
        "    data_slice = comm.scatter(data_slices, root=0)\n",
        "\n",
        "    # Step 2: Synchronize all workers using Barrier\n",
        "    comm.Barrier()\n",
        "\n",
        "    # Step 3: Each worker computes the coefficients for its slice\n",
        "    X_slice, y_slice = data_slice\n",
        "    coefficients = fit(X_slice, y_slice)\n",
        "\n",
        "    # Step 4: Gather all coefficients at the root worker\n",
        "    all_coefficients = comm.gather(coefficients, root=0)\n",
        "\n",
        "    if rank == 0:\n",
        "        # Step 5: Take the mean of the gathered coefficients\n",
        "        mean_coefficients = np.mean(all_coefficients, axis=0)\n",
        "\n",
        "        # Step 6: Use the mean coefficients to predict on the test set\n",
        "        X_test_augmented = np.c_[np.ones(x_test.shape[0]), x_test]  # Add intercept term\n",
        "        yhat_test = X_test_augmented @ mean_coefficients\n",
        "\n",
        "        # Step 7: Calculate the RMSE for the test set\n",
        "        rmse_test = calculate_rmse(y_test, yhat_test)\n",
        "        print(f\"Root Mean Squared Error (RMSE) on test set: {rmse_test}\")\n",
        "\n",
        "    return\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()\n",
        "    size_of_workers = comm.Get_size()\n",
        "\n",
        "    if rank == 0:\n",
        "        # Generate some example data\n",
        "        x_train = np.array([[1], [2], [3], [4], [5], [6], [7], [8]])\n",
        "        y_train = np.array([1, 0, 1, 0, 1, 0, 1, 0])\n",
        "\n",
        "        x_test = np.array([[1], [2], [3], [4]])\n",
        "        y_test = np.array([1, 0, 1, 0])\n",
        "    else:\n",
        "        x_train = None\n",
        "        y_train = None\n",
        "        x_test = None\n",
        "        y_test = None\n",
        "\n",
        "    scatter_gather_operations(x_train, y_train, x_test, y_test, size_of_workers)\n"
      ],
      "metadata": {
        "id": "yYXmjJB643Ra",
        "outputId": "4387d671-6d53-4896-fa54-93af9a2dc0fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "yYXmjJB643Ra",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test set: 0.48795003647426655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mpirun --allow-run-as-root --oversubscribe -np 6 python mpi_scatter_gather.py"
      ],
      "metadata": {
        "id": "GlmSl2hd5_cx"
      },
      "id": "GlmSl2hd5_cx",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expeced output not coming for script execution.\n",
        "Example below\n",
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "Root process scattering data slices to 4 workers.\n",
        "Process 0 received data slice: (array([[1], [2]]), array([1, 0]))\n",
        "Process 1 received data slice: (array([[3], [4]]), array([1, 0]))\n",
        "Process 2 received data slice: (array([[5], [6]]), array([1, 0]))\n",
        "Process 3 received data slice: (array([[7], [8]]), array([1, 0]))\n",
        "Process 0 computed coefficients: [1.0, -0.5]\n",
        "Process 1 computed coefficients: [0.5, 0.1]\n",
        "...\n",
        "Mean coefficients: [0.75, 0.05]\n",
        "Root Mean Squared Error (RMSE) on test set: 0.23\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "69A-3eGP-ObT"
      },
      "id": "69A-3eGP-ObT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hired-uniform"
      },
      "source": [
        "#### Exercise 17: Make a script and execute everything in one place (1 point)\n",
        "\n",
        "Write a script(.py) file which contains the code of all the above exercises in it so that you can run the code on multiple processes using MPI.\n",
        "\n",
        "**Hint:**\n",
        "\n",
        "- magic commands\n",
        "- put MPI related code under main function\n",
        "- !mpirun --allow-run-as-root -np 4 python filename.py"
      ],
      "id": "hired-uniform"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "motivated-national"
      },
      "source": [
        "# YOUR CODE HERE for scipt(.py)"
      ],
      "id": "motivated-national",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1:  Python Script (mpi_exercise.py)"
      ],
      "metadata": {
        "id": "8EqAd9AFADTj"
      },
      "id": "8EqAd9AFADTj"
    },
    {
      "cell_type": "code",
      "source": [
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Fit function that estimates coefficients using linear regression\n",
        "def fit(X, y):\n",
        "    X = np.c_[np.ones(X.shape[0]), X]  # Add intercept term\n",
        "    beta = np.linalg.inv(X.T @ X) @ (X.T @ y)  # Linear regression formula\n",
        "    return beta  # Coefficients including intercept\n",
        "\n",
        "# RMSE calculation function\n",
        "def calculate_rmse(y_true, y_pred):\n",
        "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
        "\n",
        "def scatter_gather_operations(x_train, y_train, x_test, y_test, size_of_workers):\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()\n",
        "\n",
        "    # Scatter the data from the root to all workers\n",
        "    data_slices = None\n",
        "    if rank == 0:\n",
        "        # Root worker creates slices to scatter\n",
        "        slice_size = len(x_train) // size_of_workers\n",
        "        data_slices = [(x_train[i * slice_size:(i + 1) * slice_size], y_train[i * slice_size:(i + 1) * slice_size])\n",
        "                       for i in range(size_of_workers)]\n",
        "        print(f\"Root process scattering data slices to {size_of_workers} workers.\")\n",
        "    else:\n",
        "        data_slices = None\n",
        "\n",
        "    # Scatter the data to all processes (including root)\n",
        "    data_slice = comm.scatter(data_slices, root=0)\n",
        "    print(f\"Process {rank} received data slice: {data_slice}\")\n",
        "\n",
        "    # Barrier to ensure all processes have received their slices before proceeding\n",
        "    comm.Barrier()\n",
        "\n",
        "    # Each worker computes the coefficients for its data slice\n",
        "    X_slice, y_slice = data_slice\n",
        "    coefficients = fit(X_slice, y_slice)\n",
        "    print(f\"Process {rank} computed coefficients: {coefficients}\")\n",
        "\n",
        "    # Predict the target (yhat) for the slice using the coefficients\n",
        "    yhat_slice = X_slice @ coefficients[1:] + coefficients[0]\n",
        "    print(f\"Process {rank} predicted yhat for its slice: {yhat_slice}\")\n",
        "\n",
        "    # Barrier to ensure all processes finish computation before gathering\n",
        "    comm.Barrier()\n",
        "\n",
        "    # Gather the coefficients back to the root process\n",
        "    all_coefficients = comm.gather(coefficients, root=0)\n",
        "\n",
        "    # Root process calculates the mean of the gathered coefficients and computes RMSE\n",
        "    if rank == 0:\n",
        "        mean_coefficients = np.mean(all_coefficients, axis=0)\n",
        "        print(f\"Mean coefficients: {mean_coefficients}\")\n",
        "\n",
        "        # Use the mean coefficients to predict on the test set\n",
        "        X_test_augmented = np.c_[np.ones(x_test.shape[0]), x_test]  # Add intercept term\n",
        "        yhat_test = X_test_augmented @ mean_coefficients\n",
        "\n",
        "        # Calculate the RMSE for the test set\n",
        "        rmse_test = calculate_rmse(y_test, yhat_test)\n",
        "        print(f\"Root Mean Squared Error (RMSE) on test set: {rmse_test}\")\n",
        "\n",
        "    return\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()\n",
        "    size_of_workers = comm.Get_size()\n",
        "\n",
        "    if rank == 0:\n",
        "        # Generate some example data\n",
        "        x_train = np.array([[1], [2], [3], [4], [5], [6], [7], [8]])\n",
        "        y_train = np.array([1, 0, 1, 0, 1, 0, 1, 0])\n",
        "\n",
        "        x_test = np.array([[1], [2], [3], [4]])\n",
        "        y_test = np.array([1, 0, 1, 0])\n",
        "    else:\n",
        "        x_train = None\n",
        "        y_train = None\n",
        "        x_test = None\n",
        "        y_test = None\n",
        "\n",
        "    scatter_gather_operations(x_train, y_train, x_test, y_test, size_of_workers)\n"
      ],
      "metadata": {
        "id": "Upb84Jn0_8JK"
      },
      "id": "Upb84Jn0_8JK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Save the Script as mpi_exercise.py"
      ],
      "metadata": {
        "id": "Gkw3E4sJAHsS"
      },
      "id": "Gkw3E4sJAHsS"
    },
    {
      "cell_type": "code",
      "source": [
        "script_code = \"\"\"\n",
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Fit function that estimates coefficients using linear regression\n",
        "def fit(X, y):\n",
        "    X = np.c_[np.ones(X.shape[0]), X]  # Add intercept term\n",
        "    beta = np.linalg.inv(X.T @ X) @ (X.T @ y)  # Linear regression formula\n",
        "    return beta  # Coefficients including intercept\n",
        "\n",
        "# RMSE calculation function\n",
        "def calculate_rmse(y_true, y_pred):\n",
        "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
        "\n",
        "def scatter_gather_operations(x_train, y_train, x_test, y_test, size_of_workers):\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()\n",
        "\n",
        "    # Scatter the data from the root to all workers\n",
        "    data_slices = None\n",
        "    if rank == 0:\n",
        "        # Root worker creates slices to scatter\n",
        "        slice_size = len(x_train) // size_of_workers\n",
        "        data_slices = [(x_train[i * slice_size:(i + 1) * slice_size], y_train[i * slice_size:(i + 1) * slice_size)]\n",
        "                       for i in range(size_of_workers)]\n",
        "        print(f\"Root process scattering data slices to {size_of_workers} workers.\")\n",
        "    else:\n",
        "        data_slices = None\n",
        "\n",
        "    # Scatter the data to all processes (including root)\n",
        "    data_slice = comm.scatter(data_slices, root=0)\n",
        "    print(f\"Process {rank} received data slice: {data_slice}\")\n",
        "\n",
        "    # Barrier to ensure all processes have received their slices before proceeding\n",
        "    comm.Barrier()\n",
        "\n",
        "    # Each worker computes the coefficients for its data slice\n",
        "    X_slice, y_slice = data_slice\n",
        "    coefficients = fit(X_slice, y_slice)\n",
        "    print(f\"Process {rank} computed coefficients: {coefficients}\")\n",
        "\n",
        "    # Predict the target (yhat) for the slice using the coefficients\n",
        "    yhat_slice = X_slice @ coefficients[1:] + coefficients[0]\n",
        "    print(f\"Process {rank} predicted yhat for its slice: {yhat_slice}\")\n",
        "\n",
        "    # Barrier to ensure all processes finish computation before gathering\n",
        "    comm.Barrier()\n",
        "\n",
        "    # Gather the coefficients back to the root process\n",
        "    all_coefficients = comm.gather(coefficients, root=0)\n",
        "\n",
        "    # Root process calculates the mean of the gathered coefficients and computes RMSE\n",
        "    if rank == 0:\n",
        "        mean_coefficients = np.mean(all_coefficients, axis=0)\n",
        "        print(f\"Mean coefficients: {mean_coefficients}\")\n",
        "\n",
        "        # Use the mean coefficients to predict on the test set\n",
        "        X_test_augmented = np.c_[np.ones(x_test.shape[0]), x_test]  # Add intercept term\n",
        "        yhat_test = X_test_augmented @ mean_coefficients\n",
        "\n",
        "        # Calculate the RMSE for the test set\n",
        "        rmse_test = calculate_rmse(y_test, yhat_test)\n",
        "        print(f\"Root Mean Squared Error (RMSE) on test set: {rmse_test}\")\n",
        "\n",
        "    return\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    comm = MPI.COMM_WORLD\n",
        "    rank = comm.Get_rank()\n",
        "    size_of_workers = comm.Get_size()\n",
        "\n",
        "    if rank == 0:\n",
        "        # Generate some example data\n",
        "        x_train = np.array([[1], [2], [3], [4], [5], [6], [7], [8]])\n",
        "        y_train = np.array([1, 0, 1, 0, 1, 0, 1, 0])\n",
        "\n",
        "        x_test = np.array([[1], [2], [3], [4]])\n",
        "        y_test = np.array([1, 0, 1, 0])\n",
        "    else:\n",
        "        x_train = None\n",
        "        y_train = None\n",
        "        x_test = None\n",
        "        y_test = None\n",
        "\n",
        "    scatter_gather_operations(x_train, y_train, x_test, y_test, size_of_workers)\n",
        "\"\"\"\n",
        "\n",
        "with open(\"mpi_exercise.py\", \"w\") as f:\n",
        "    f.write(script_code)\n"
      ],
      "metadata": {
        "id": "l3H2KfwzAIa0"
      },
      "id": "l3H2KfwzAIa0",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Run the Script with mpirun"
      ],
      "metadata": {
        "id": "z0cNv4cgARBh"
      },
      "id": "z0cNv4cgARBh"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "experimental-waterproof",
        "scrolled": true
      },
      "source": [
        "# YOUR CODE HERE for MPI command\n",
        "\n",
        "!mpirun --allow-run-as-root --oversubscribe -np 4 python mpi_exercise.py"
      ],
      "id": "experimental-waterproof",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected output not coming while running on colab."
      ],
      "metadata": {
        "id": "hryKfbj7AewR"
      },
      "id": "hryKfbj7AewR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "protecting-assets"
      },
      "source": [
        "#### Exercise 18: Use Sklearn to compare (1 point)\n",
        "\n",
        "Apply the Linear regression on the given data using sklearn package and compare with the above results\n",
        "\n",
        "**Hint:**\n",
        "* Split the data into train and test\n",
        "* Fit the train data and predict the test data using `sklearn Linear Regression`\n",
        "* Compare the coefficients and intercept with above estimated coefficients\n",
        "* calculate loss (RMSE) on test data and predictions and compare"
      ],
      "id": "protecting-assets"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "applicable-tyler"
      },
      "source": [
        "# YOUR CODE HERE"
      ],
      "id": "applicable-tyler",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Function to compare custom linear regression and sklearn's linear regression\n",
        "def compare_with_sklearn(x_train, y_train, x_test, y_test):\n",
        "    # Step 1: Apply Sklearn's Linear Regression\n",
        "    model = LinearRegression()\n",
        "    model.fit(x_train, y_train)  # Fit the model using training data\n",
        "\n",
        "    # Step 2: Get the coefficients and intercept from the sklearn model\n",
        "    sklearn_coefficients = model.coef_\n",
        "    sklearn_intercept = model.intercept_\n",
        "    print(f\"Sklearn Coefficients: {sklearn_coefficients}\")\n",
        "    print(f\"Sklearn Intercept: {sklearn_intercept}\")\n",
        "\n",
        "    # Step 3: Predict the test data\n",
        "    yhat_sklearn = model.predict(x_test)\n",
        "\n",
        "    # Step 4: Calculate RMSE for Sklearn model\n",
        "    rmse_sklearn = np.sqrt(mean_squared_error(y_test, yhat_sklearn))\n",
        "    print(f\"Sklearn RMSE: {rmse_sklearn}\")\n",
        "\n",
        "    return sklearn_coefficients, sklearn_intercept, rmse_sklearn\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example data\n",
        "    x_train = np.array([[1], [2], [3], [4], [5], [6], [7], [8]])\n",
        "    y_train = np.array([1, 0, 1, 0, 1, 0, 1, 0])\n",
        "\n",
        "    x_test = np.array([[1], [2], [3], [4]])\n",
        "    y_test = np.array([1, 0, 1, 0])\n",
        "\n",
        "    # Step 5: Compare results\n",
        "    sklearn_coefficients, sklearn_intercept, rmse_sklearn = compare_with_sklearn(x_train, y_train, x_test, y_test)\n",
        "\n",
        "    # You can now compare this with the custom implementation from Exercise 16\n"
      ],
      "metadata": {
        "id": "8l1ET9VrBAhz",
        "outputId": "9622e9de-f88f-46f0-d189-1a6380fb2d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8l1ET9VrBAhz",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn Coefficients: [-0.04761905]\n",
            "Sklearn Intercept: 0.7142857142857144\n",
            "Sklearn RMSE: 0.4879500364742666\n"
          ]
        }
      ]
    }
  ]
}